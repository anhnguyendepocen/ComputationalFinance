{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"text-align: center; font-size: 300%\"> Computational Finance </p>\n",
    "<img src=\"img/ABSlogo.svg\" alt=\"LOGO\" style=\"display:block; margin-left: auto; margin-right: auto; width: 50%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced Monte Carlo Methods\n",
    "## Variance Reduction Techniques\n",
    "* In standard Monte Carlo, the length of the confidence interval for $\\theta\\equiv\\mathbb{E}[X]$ is proportional to $\\hat{\\sigma}/\\sqrt{n}$, where $\\sigma$ is the standard deviation of $X$.\n",
    "* Thus to increase the accuracy by a factor 10 (i.e., gain 1 digit), we need 100 times as many samples.\n",
    "* Variance reduction techniques aim to improve the accuracy of the estimate, without increasing $n$.\n",
    "* We will consider two such techniques: *antithetic sampling*, and *control variates*.\n",
    "* Another powerful technique is *importance sampling*, but this is beyond the scope of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Antithetic Sampling\n",
    "* The crude MC estimate for $\\theta\\equiv \\mathbb{E} [X]$, based on $n$ independent draws $X_i$, is\n",
    "$$\n",
    "\\hat{\\theta}=\\frac{1}{n}\\sum_{i=1}^n X_i,\n",
    "$$\n",
    "* Now suppose that we can somehow sample $n$ pairs $(X_i, \\tilde X_i)$, such that\n",
    "  * both $X_i$ and $\\tilde X_i$ are drawn from the distribution of $X$;\n",
    "  * the *pairs* $(X_i, \\tilde X_i)$ are independent across $i$;\n",
    "  * for each $i$, $X_i$ and $\\tilde X_i$ are (negatively) correlated.\n",
    "* The antithetic variable estimator is then\n",
    "$$\n",
    "\\hat{\\theta}_{AV}=\\frac{1}{2}\\left(\\frac{1}{n}\\sum_{i=1}^n X_i+\\frac{1}{n}\\sum_{i=1}^n \\tilde X_i\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Rewriting the estimator as\n",
    "$$\n",
    "\\hat{\\theta}_{AV}=\\frac{1}{n}\\sum_{i=1}^n\\left(\\frac{X_i+\\tilde X_i}{2}\\right),\n",
    "$$\n",
    "we see that it is unbiased, and that $\\hat{\\theta}_{AV}$ is the mean of $n$ independent observations, $(X_i+\\tilde X_i)/2$, so that the LLN and CLT continue to apply.\n",
    "* Hence, by the CLT,\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\theta}_{AV}-\\theta)\\stackrel d \\rightarrow N(0,\\sigma^2_{AV}),\n",
    "$$\n",
    "where\n",
    "\\begin{align*}\n",
    "\\sigma^2_{AV}&=\\mathrm{Var}\\left[\\frac{X_i+\\tilde X_i}{2}\\right]=\\frac{1}{4}\\left(\\mathrm{Var}[X_i]+\\mathrm{Var}[\\tilde X_i] +2\\mathrm{Cov}[X_i,\\tilde X_i]\\right)\\\\\n",
    "%&=\\frac{1}{2}\\left[\\mathrm{Var}[X_i] +\\mathrm{Cov}[X_i,\\tilde X_i]\\right)\n",
    "&=\\frac{\\sigma^2}{2}\\big(1+\\rho(X_i,\\tilde X_i)\\big).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Comparing the variance of $\\hat{\\theta}_{AV}$, $\\frac{1}{n}\\sigma^2_{AV}$, with that of the crude estimator based on $2n$ observations $\\left(\\frac{1}{2n}\\sigma^2\\right)$, we see that efficiency is gained whenever the correlation $\\rho(X_i,\\tilde X_i)$ is negative.\n",
    "* So how do we draw correlated random numbers $X_i$ and $\\tilde X_i$?\n",
    "* Our simulations are typically based on an array of standard normal random numbers $\\mathbf{z}_i$, i.e., $X_i=f(\\mathbf{z}_i)$. Setting $\\tilde X_i=f(-\\mathbf{z}_i)$ will often do the trick. \n",
    "* Note for standard Brownian motion, this corresponds to flipping the path about the abscissa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmsim_vec(T, N, X0=0, mu=0, sigma=1, numsim=1, av=False):\n",
    "    \"\"\"Simulate `numsim` Brownian motion paths. If av=True, then 2*`numsim` paths are returned,\n",
    "    where paths numsim:2numsim+1 are antithetic paths.\n",
    "    \"\"\"\n",
    "    deltaT = float(T)/N\n",
    "    tvec = np.linspace(0, T, N+1)\n",
    "    z = np.random.randn(numsim, N+1)\n",
    "    if av:\n",
    "        z=np.concatenate((z, -z))\n",
    "    dX = mu*deltaT + sigma*np.sqrt(deltaT)*z\n",
    "    dX[:, 0] = 0.\n",
    "    X = np.cumsum(dX, axis=1)\n",
    "    X += X0    \n",
    "    return tvec, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asianmc_vec(S0, K, T, r, sigma, delta, N, numsim=1000, av=False):\n",
    "    \"\"\"\n",
    "    Monte Carlo price of an arithmetic average Asian call.\n",
    "    \"\"\"\n",
    "    X0 = np.log(S0)\n",
    "    nu = r-delta-.5*sigma**2    \n",
    "    _, X = bmsim_vec(T, N, X0, nu, sigma, numsim, av)\n",
    "    S = np.exp(X)\n",
    "    payoffs = np.maximum(S[:, 1:].mean(axis=1)-K, 0.)\n",
    "    g = np.exp(-r*T)*payoffs\n",
    "    if av:\n",
    "        g=.5*(g[:numsim]+g[numsim:])    \n",
    "    C = g.mean();s = g.std()\n",
    "    zq = norm.ppf(0.975)\n",
    "    Cl = C - zq/np.sqrt(numsim)*s\n",
    "    Cu = C + zq/np.sqrt(numsim)*s\n",
    "    return C, Cl, Cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0927262054551385, 0.03592162508407748)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S0=11; K=10; T=3/12.; r=0.02; sigma=.3; delta=0.01; N=10; numsim=10**4\n",
    "np.random.seed(0)\n",
    "C, Cl, Cu=asianmc_vec(S0, K, T, r, sigma, delta, N, numsim, False)\n",
    "C, Cu-Cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0824190804865295, 0.012604081385357624)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "C, Cl, Cu=asianmc_vec(S0, K, T, r, sigma, delta, N, numsim/2, True)\n",
    "C, Cu-Cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "livereveal": {
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
